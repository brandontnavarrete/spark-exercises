{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b08241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 09:11:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark  \n",
    "import regex\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cb00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1706396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5141f77e",
   "metadata": {},
   "source": [
    "# Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "raw",
   "id": "14dc4028",
   "metadata": {},
   "source": [
    "The name of the column should be language\n",
    "View the schema of the dataframe\n",
    "Output the shape of the dataframe\n",
    "Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7adb4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {'languages': [ \"python\",'c++','java','r','javascript']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "413cb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b523d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e3ba61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'languages'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column name\n",
    "df.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f578029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- languages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "460a0662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[languages: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37fc77bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| languages|\n",
      "+----------+\n",
      "|    python|\n",
      "|       c++|\n",
      "|      java|\n",
      "|         r|\n",
      "|javascript|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show first 5 records\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946aac0",
   "metadata": {},
   "source": [
    "# Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0255ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "mpg = spark.createDataFrame(data('mpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80602214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|auto(l5)|  f| 18| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9f8f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2053f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1 column of output that contains a message like the one below:\n",
    "# The 1999 audi a4 has a 4 cylinder engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1446b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|description                              |\n",
      "+-----------------------------------------+\n",
      "|The1999 audi has a 4 cylinder engine     |\n",
      "|The1999 audi has a 4 cylinder engine     |\n",
      "|The2008 audi has a 4 cylinder engine     |\n",
      "|The2008 audi has a 4 cylinder engine     |\n",
      "|The1999 audi has a 6 cylinder engine     |\n",
      "|The1999 audi has a 6 cylinder engine     |\n",
      "|The2008 audi has a 6 cylinder engine     |\n",
      "|The1999 audi has a 4 cylinder engine     |\n",
      "|The1999 audi has a 4 cylinder engine     |\n",
      "|The2008 audi has a 4 cylinder engine     |\n",
      "|The2008 audi has a 4 cylinder engine     |\n",
      "|The1999 audi has a 6 cylinder engine     |\n",
      "|The1999 audi has a 6 cylinder engine     |\n",
      "|The2008 audi has a 6 cylinder engine     |\n",
      "|The2008 audi has a 6 cylinder engine     |\n",
      "|The1999 audi has a 6 cylinder engine     |\n",
      "|The2008 audi has a 6 cylinder engine     |\n",
      "|The2008 audi has a 8 cylinder engine     |\n",
      "|The2008 chevrolet has a 8 cylinder engine|\n",
      "|The2008 chevrolet has a 8 cylinder engine|\n",
      "+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(lit('The'),mpg.year, lit(' '), mpg.manufacturer, lit(' has a '), mpg.cyl, lit(' cylinder engine')).alias('description')).show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a7fa329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_extract(\"address\", r\"^(\\d+)\", 1).alias(\"street_no\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9eababb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| trans|\n",
      "+------+\n",
      "|  auto|\n",
      "|manual|\n",
      "|manual|\n",
      "|  auto|\n",
      "|  auto|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "mpg.withColumn('trans', when(mpg.trans.like('auto%'), 'auto').otherwise('manual')).select('trans').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7d97b",
   "metadata": {},
   "source": [
    "# Load the tips dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e24712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94aa5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72ec58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(smoker)|\n",
      "+-------------+\n",
      "|          244|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.select(count(tips.smoker)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7897dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f764f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18695d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------------+\n",
      "|smoker|count|           percent|\n",
      "+------+-----+------------------+\n",
      "|    No|  151|61.885245901639344|\n",
      "|   Yes|   93|38.114754098360656|\n",
      "+------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupby('smoker').count().withColumn(\n",
    "    'percent',\n",
    "        col('count') / tips.count() * 100).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19338a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a column that contains the tip percentage\n",
    "tips.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7dff8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|     tip percentage|\n",
      "+-------------------+\n",
      "|0.05944673337257211|\n",
      "|0.16054158607350097|\n",
      "|0.16658733936220846|\n",
      "| 0.1397804054054054|\n",
      "|0.14680764538430255|\n",
      "|0.18623962040332148|\n",
      "|0.22805017103762829|\n",
      "|0.11607142857142858|\n",
      "|0.13031914893617022|\n",
      "| 0.2185385656292287|\n",
      "+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.select(( tips.tip / tips.total_bill ).alias('tip percentage')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "463948d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+\n",
      "|   sex|smoker|count|\n",
      "+------+------+-----+\n",
      "|  Male|    No|   97|\n",
      "|  Male|   Yes|   60|\n",
      "|Female|    No|   54|\n",
      "|Female|   Yes|   33|\n",
      "+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tip percentage for each combination of sex and smoker.\n",
    "tips.groupBy('sex', 'smoker').count().show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f847f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c710118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+\n",
      "|   sex|smoker|avg_tip_p|\n",
      "+------+------+---------+\n",
      "|  Male|    No|   0.1607|\n",
      "|  Male|   Yes|   0.1528|\n",
      "|Female|    No|   0.1569|\n",
      "|Female|   Yes|   0.1822|\n",
      "+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.withColumn('tip_percentage', tips.tip / tips.total_bill).groupby(\n",
    "    'sex','smoker').agg(\n",
    "        F.round(\n",
    "            F.mean('tip_percentage'),4).alias(\n",
    "                'avg_tip_p')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a6c92",
   "metadata": {},
   "source": [
    "# Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7a6ed09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce49362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+-----------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|fahrenheit_|\n",
      "+----------+-------------+--------+--------+----+-------+-----------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|       55.0|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|       51.0|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|       53.0|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|       54.0|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|       48.0|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|       40.0|\n",
      "|2012-01-07|          0.0|     7.2|     2.8| 2.3|   rain|       45.0|\n",
      "|2012-01-08|          0.0|    10.0|     2.8| 2.0|    sun|       50.0|\n",
      "|2012-01-09|          4.3|     9.4|     5.0| 3.4|   rain|       49.0|\n",
      "|2012-01-10|          1.0|     6.1|     0.6| 3.4|   rain|       43.0|\n",
      "|2012-01-11|          0.0|     6.1|    -1.1| 5.1|    sun|       43.0|\n",
      "|2012-01-12|          0.0|     6.1|    -1.7| 1.9|    sun|       43.0|\n",
      "|2012-01-13|          0.0|     5.0|    -2.8| 1.3|    sun|       41.0|\n",
      "|2012-01-14|          4.1|     4.4|     0.6| 5.3|   snow|       40.0|\n",
      "|2012-01-15|          5.3|     1.1|    -3.3| 3.2|   snow|       34.0|\n",
      "|2012-01-16|          2.5|     1.7|    -2.8| 5.0|   snow|       35.0|\n",
      "|2012-01-17|          8.1|     3.3|     0.0| 5.6|   snow|       38.0|\n",
      "|2012-01-18|         19.8|     0.0|    -2.8| 5.0|   snow|       32.0|\n",
      "|2012-01-19|         15.2|    -1.1|    -2.8| 1.6|   snow|       30.0|\n",
      "|2012-01-20|         13.5|     7.2|    -1.1| 2.3|   snow|       45.0|\n",
      "+----------+-------------+--------+--------+----+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn('fahrenheit_', F.round((weather.temp_max * 1.8) + 32)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9a6796e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+--------------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|fahrenheit_min|\n",
      "+----------+-------------+--------+--------+----+-------+--------------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|          41.0|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|          37.0|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|          45.0|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|          42.0|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|          37.0|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|          36.0|\n",
      "|2012-01-07|          0.0|     7.2|     2.8| 2.3|   rain|          37.0|\n",
      "|2012-01-08|          0.0|    10.0|     2.8| 2.0|    sun|          37.0|\n",
      "|2012-01-09|          4.3|     9.4|     5.0| 3.4|   rain|          41.0|\n",
      "|2012-01-10|          1.0|     6.1|     0.6| 3.4|   rain|          33.0|\n",
      "|2012-01-11|          0.0|     6.1|    -1.1| 5.1|    sun|          30.0|\n",
      "|2012-01-12|          0.0|     6.1|    -1.7| 1.9|    sun|          29.0|\n",
      "|2012-01-13|          0.0|     5.0|    -2.8| 1.3|    sun|          27.0|\n",
      "|2012-01-14|          4.1|     4.4|     0.6| 5.3|   snow|          33.0|\n",
      "|2012-01-15|          5.3|     1.1|    -3.3| 3.2|   snow|          26.0|\n",
      "|2012-01-16|          2.5|     1.7|    -2.8| 5.0|   snow|          27.0|\n",
      "|2012-01-17|          8.1|     3.3|     0.0| 5.6|   snow|          32.0|\n",
      "|2012-01-18|         19.8|     0.0|    -2.8| 5.0|   snow|          27.0|\n",
      "|2012-01-19|         15.2|    -1.1|    -2.8| 1.6|   snow|          27.0|\n",
      "|2012-01-20|         13.5|     7.2|    -1.1| 2.3|   snow|          30.0|\n",
      "+----------+-------------+--------+--------+----+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn('fahrenheit_min', F.round((weather.temp_min * 1.8) + 32)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c593316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|month|           avg_rain|\n",
      "+-----+-------------------+\n",
      "|    7|0.38870967741935486|\n",
      "|    6| 1.1075000000000002|\n",
      "|    8| 1.3201612903225806|\n",
      "|    5| 1.6733870967741935|\n",
      "|    9| 1.9624999999999997|\n",
      "|    4|  3.128333333333333|\n",
      "|    2|  3.734513274336283|\n",
      "|    1| 3.7580645161290316|\n",
      "|   10|  4.059677419354839|\n",
      "|    3|  4.888709677419355|\n",
      "|   12|  5.021774193548388|\n",
      "|   11|  5.354166666666667|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "weather.withColumn('month', F.month(weather.date)).groupBy(F.col('month')).agg(F.mean(weather.precipitation).alias('avg_rain')).sort(F.col('avg_rain')).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "607953ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(year=2012, avg_wind=3.400819672131147)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "weather.withColumn('year', F.year(weather.date)\n",
    ").groupby(F.col('year')).agg(F.mean(weather.wind).alias('avg_wind')).sort(\n",
    "            F.col('avg_wind').desc()\n",
    "            ).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9809138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "weather.filter(\n",
    "    F.month(weather.date) == 1\n",
    "    ).groupby(\n",
    "    weather.weather\n",
    "    ).count().sort(\n",
    "        F.col('count').desc()\n",
    "        ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a40906dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "| average_high_temp| average_low_temp|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "(weather.filter(F.month(\"date\") == 7)\n",
    "    .filter(F.year(\"date\") > 2012)\n",
    "    .filter(F.year(\"date\") < 2015)\n",
    "    .filter(F.col(\"weather\") == F.lit(\"sun\"))\n",
    "    .agg(\n",
    "        F.avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        F.avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b37ada30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "(weather.filter(F.year('date') == 2015)\n",
    "    .filter(F.quarter('date') == 3)\n",
    "    .select(\n",
    "        F.when(\n",
    "            F.col('weather') == 'rain', 1\n",
    "            ).otherwise(0).alias('rain'))\n",
    "    .agg(F.mean('rain')).show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "42603841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|      avg(did_rain)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "(weather.withColumn('year', F.year('date')).select(\n",
    "        F.when(\n",
    "            F.col('precipitation') > 0, 1\n",
    "            ).otherwise(0).alias('did_rain'), 'year'\n",
    "            )\n",
    "    .groupby('year')\n",
    "    .agg(F.mean('did_rain'))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43374dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
